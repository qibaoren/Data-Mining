{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcac9b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:45:43.019589Z",
     "start_time": "2022-05-06T14:45:43.016597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try a Support Vector Machine regressor with various hyperparameters, such as kernel=\"linear\" or kernel=\"rbf\"\n",
    "# Try replacing GridSearchCV with RandomizedSearchCV\n",
    "# Try adding a transformer in the preparation pipeline to select only the most important attributes\n",
    "# Try creating a single pipeline that doeas full data preparation plus the final prediction\n",
    "# Automatically explore sopme preparations options using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3bff00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:39:48.080205Z",
     "start_time": "2022-05-08T06:39:46.591227Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def train_test_StratifiedShuffleSplit():\n",
    "    # the work of  spliting train/test set has been finished\n",
    "    # housing = pd.read_csv(\n",
    "    # \"F:/jupyter_notebook_home/Linear_Regression/datasets/housing/housing.csv\")\n",
    "    housing = pd.read_csv(\n",
    "         \"G:/jupyter_notebook/Linear Regression/datasets/housing/housing.csv\")\n",
    "    housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                              bins=[0., 1.5, 3., 4.5, 6., np.inf],\n",
    "                              labels=[1, 2, 3, 4, 5])\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "        strat_train_set = housing.loc[train_index]\n",
    "        strat_test_set  = housing.loc[test_index]\n",
    "    for set_ in (strat_train_set, strat_test_set):\n",
    "        set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "    housing = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "    housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "    housing_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "    housing__test_labels = strat_test_set[\"median_house_value\"].copy()\n",
    "    return housing, housing_labels, housing_test, housing__test_labels\n",
    "housing, housing_labels, housing_test, housing__test_labels = train_test_StratifiedShuffleSplit()\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):      \n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:,households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"attribs_adder\", CombinedAttributesAdder()),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a Support Vector Machine regressor with various hyperparameters, such as kernel=\"linear\" or kernel=\"rbf\"\n",
    "param_grid = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [0.01, 0.03, 0.1, 0.3, 1.0, 3.0], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "    {\"kernel\": [\"linear\"], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "]\n",
    "svr = SVR()\n",
    "grid_search = GridSearchCV(svr, param_grid, cv=5, scoring=\"neg_mean_squared_error\",verbose=2)\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "negative_mse = grid_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "print(rmse)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee288118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T15:04:27.774556Z",
     "start_time": "2022-05-07T15:04:27.526210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expon_distrib = expon(scale=1.)\n",
    "samples = expon_distrib.rvs(1000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Exponential distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bf0ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T16:39:18.809121Z",
     "start_time": "2022-05-06T15:38:59.925484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   6.2s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   6.3s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   6.3s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   6.3s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   6.4s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  13.2s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  13.4s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  13.3s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  13.5s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  13.7s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  11.9s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  11.9s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  11.8s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  11.9s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  12.0s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   6.3s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   6.2s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   6.4s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   6.3s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   6.3s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  12.5s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  12.6s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  12.6s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  12.5s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  12.6s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   6.3s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   6.2s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   6.2s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   6.2s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   6.2s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  11.2s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  22.5s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  23.7s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  26.1s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  22.2s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  23.9s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  11.3s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  12.0s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  11.5s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  10.8s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  10.3s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=  37.0s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=  30.0s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=  35.6s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=  40.2s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=  28.0s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   7.2s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   7.3s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   7.4s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   7.2s\n",
      "[CV] END C=5385.293820172355, gamma=0.18696125197741642, kernel=linear; total time=   7.2s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=  12.0s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=  11.9s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=  12.0s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=  11.9s\n",
      "[CV] END C=22.59903216621323, gamma=2.850796878935603, kernel=rbf; total time=  12.0s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=  12.9s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=  12.8s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=  13.3s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=  12.4s\n",
      "[CV] END C=34246.75194632794, gamma=0.3632878599687583, kernel=linear; total time=  11.4s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=167.7278956080511, gamma=0.2757870542258224, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   6.2s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   6.2s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   6.2s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   6.2s\n",
      "[CV] END C=61.54360542501371, gamma=0.6835472281341501, kernel=linear; total time=   6.2s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=98.73897389920914, gamma=0.4960365360493639, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=  11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=8935.505635947808, gamma=0.37354658165762367, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   6.2s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   6.2s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   6.2s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   6.3s\n",
      "[CV] END C=135.76775824842434, gamma=0.838636245624803, kernel=linear; total time=   6.1s\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time= 2.2min\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time= 1.7min\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time= 1.6min\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time= 1.9min\n",
      "[CV] END C=151136.20282548846, gamma=1.4922453771381408, kernel=rbf; total time= 1.9min\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   6.2s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   6.3s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   6.3s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   6.2s\n",
      "[CV] END C=761.4316758498783, gamma=2.6126336514161914, kernel=linear; total time=   6.3s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=  25.0s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=  23.1s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=  39.5s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=  23.9s\n",
      "[CV] END C=97392.81883041795, gamma=0.09265545895311562, kernel=linear; total time=  19.5s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   6.7s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   6.8s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   6.6s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   6.7s\n",
      "[CV] END C=2423.0759984939164, gamma=3.248614270240346, kernel=linear; total time=   6.4s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   6.2s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   6.1s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   6.3s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   6.3s\n",
      "[CV] END C=717.3632997255095, gamma=0.3165604432088257, kernel=linear; total time=   6.2s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=  12.3s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=  12.2s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=  12.2s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=  12.3s\n",
      "[CV] END C=4446.667521184072, gamma=3.3597284456608496, kernel=rbf; total time=  12.3s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   6.6s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   6.8s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   6.9s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   6.6s\n",
      "[CV] END C=2963.564121207815, gamma=0.15189814782062885, kernel=linear; total time=   6.6s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   6.0s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   6.1s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   6.1s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   6.2s\n",
      "[CV] END C=91.64267381686706, gamma=0.01575994483585621, kernel=linear; total time=   6.0s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=24547.601975705915, gamma=0.22153944050588595, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=22.76927941060928, gamma=0.22169760231351215, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   9.4s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   8.9s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   9.4s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   9.2s\n",
      "[CV] END C=16483.850529752886, gamma=1.4752145260435134, kernel=linear; total time=   8.4s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=  42.5s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=  40.7s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=  51.9s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=  54.1s\n",
      "[CV] END C=101445.66881340064, gamma=1.052904084582266, kernel=rbf; total time=  45.1s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=  18.9s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=  19.0s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=  18.8s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=  20.6s\n",
      "[CV] END C=56681.80859029545, gamma=0.9763011917123741, kernel=rbf; total time=  19.8s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=48.15822390928914, gamma=0.4633351167983427, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=  11.2s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=399.7268155705774, gamma=1.3078757839577408, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   6.1s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   6.2s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   6.2s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   6.2s\n",
      "[CV] END C=251.14073886281363, gamma=0.8238105204914145, kernel=linear; total time=   6.2s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   6.1s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   6.1s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   6.2s\n",
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   6.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=60.17373642891687, gamma=1.2491263443165994, kernel=linear; total time=   6.1s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=15415.161544891856, gamma=0.2691677514619319, kernel=rbf; total time=  11.8s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   6.6s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   6.7s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   6.7s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   6.6s\n",
      "[CV] END C=1888.9148509967113, gamma=0.739678838777267, kernel=linear; total time=   6.6s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   6.2s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   6.2s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   6.1s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   6.2s\n",
      "[CV] END C=55.53838911232773, gamma=0.578634378499143, kernel=linear; total time=   6.1s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=  11.4s\n",
      "[CV] END C=26.714480823948186, gamma=1.0117295509275495, kernel=rbf; total time=  11.3s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   7.2s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   7.0s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   7.0s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   7.0s\n",
      "[CV] END C=3582.0552780489566, gamma=1.1891370222133257, kernel=linear; total time=   6.8s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   6.2s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   6.1s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   6.2s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   6.3s\n",
      "[CV] END C=198.7004781812736, gamma=0.5282819748826726, kernel=linear; total time=   6.1s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   6.3s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   6.1s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   6.3s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   6.3s\n",
      "[CV] END C=129.8000604143307, gamma=2.8621383676481322, kernel=linear; total time=   6.3s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=  11.8s\n",
      "[CV] END C=288.4269299593897, gamma=0.17580835850006285, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   7.4s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   7.2s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   7.4s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   7.4s\n",
      "[CV] END C=6287.039489427172, gamma=0.3504567255332862, kernel=linear; total time=   7.1s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=  33.8s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=  38.2s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=  36.2s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=  36.7s\n",
      "[CV] END C=61217.04421344494, gamma=1.6279689407405564, kernel=rbf; total time=  34.5s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=  11.6s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=  11.5s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=  11.7s\n",
      "[CV] END C=926.9787684096649, gamma=2.147979593060577, kernel=rbf; total time=  11.8s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=  12.1s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=  13.3s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=  12.7s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=  12.8s\n",
      "[CV] END C=33946.157064934, gamma=2.2642426492862313, kernel=linear; total time=  11.5s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=  29.1s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=  21.3s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=  32.6s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=  20.7s\n",
      "[CV] END C=84789.82947739525, gamma=0.3176359085304841, kernel=linear; total time=  17.2s\n",
      "54767.960710084124\n",
      "{'C': 157055.10989448498, 'gamma': 0.26497040005002437, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Try replacing GridSearchCV with RandomizedSearchCV\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)\n",
    "negative_mse = rnd_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "print(rmse)\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "955fbadf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:43:51.724625Z",
     "start_time": "2022-05-08T06:43:51.718639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try adding a transformer in the preparation pipeline to select only the most important attributes\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]\n",
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5dc7e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:50:06.358541Z",
     "start_time": "2022-05-08T06:49:25.678111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END ...................max_features=7, n_estimators=180; total time=   4.4s\n",
      "[CV] END ...................max_features=7, n_estimators=180; total time=   4.4s\n",
      "[CV] END ....................max_features=5, n_estimators=15; total time=   0.2s\n",
      "[CV] END ....................max_features=5, n_estimators=15; total time=   0.2s\n",
      "[CV] END ....................max_features=3, n_estimators=72; total time=   0.9s\n",
      "[CV] END ....................max_features=3, n_estimators=72; total time=   0.9s\n",
      "[CV] END ....................max_features=5, n_estimators=21; total time=   0.3s\n",
      "[CV] END ....................max_features=5, n_estimators=21; total time=   0.3s\n",
      "[CV] END ...................max_features=7, n_estimators=122; total time=   3.0s\n",
      "[CV] END ...................max_features=7, n_estimators=122; total time=   3.0s\n",
      "[CV] END ....................max_features=3, n_estimators=75; total time=   0.9s\n",
      "[CV] END ....................max_features=3, n_estimators=75; total time=   0.9s\n",
      "[CV] END ....................max_features=3, n_estimators=88; total time=   1.1s\n",
      "[CV] END ....................max_features=3, n_estimators=88; total time=   1.1s\n",
      "[CV] END ...................max_features=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END ...................max_features=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END ...................max_features=3, n_estimators=150; total time=   2.0s\n",
      "[CV] END ...................max_features=3, n_estimators=150; total time=   2.0s\n",
      "[CV] END .....................max_features=5, n_estimators=2; total time=   0.0s\n",
      "[CV] END .....................max_features=5, n_estimators=2; total time=   0.0s\n",
      "51043.943000423824 {'max_features': 7, 'n_estimators': 180}\n",
      "53571.87639695895 {'max_features': 5, 'n_estimators': 15}\n",
      "52513.173484690014 {'max_features': 3, 'n_estimators': 72}\n",
      "52991.61398062229 {'max_features': 5, 'n_estimators': 21}\n",
      "51156.11344258365 {'max_features': 7, 'n_estimators': 122}\n",
      "52385.31094400939 {'max_features': 3, 'n_estimators': 75}\n",
      "52516.7949691823 {'max_features': 3, 'n_estimators': 88}\n",
      "51130.11538597024 {'max_features': 5, 'n_estimators': 100}\n",
      "51994.685540133396 {'max_features': 3, 'n_estimators': 150}\n",
      "65604.998926642 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.94135046,  1.34743822, -0.8936472 ,  0.00622264,  1.        ],\n",
       "       [ 1.17178212, -1.19243966,  1.292168  , -0.04081077,  0.        ],\n",
       "       [ 0.26758118, -0.1259716 , -0.52543365, -0.07537122,  1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=2, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)\n",
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "\n",
    "k = 5\n",
    "feature_importances=rnd_search.best_estimator_.feature_importances_\n",
    "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "top_k_feature_indices\n",
    "np.array(attributes)[top_k_feature_indices]\n",
    "sorted(zip(feature_importances, attributes), reverse=True)[:k]\n",
    "\n",
    "preparation_and_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
    "])\n",
    "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)\n",
    "housing_prepared_top_k_features[0:3]\n",
    "housing_prepared[0:3, top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef09c995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:03:46.293939Z",
     "start_time": "2022-05-08T07:02:47.502157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   3.4s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   3.4s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   9.2s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=   9.2s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   8.7s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=   8.6s\n"
     ]
    }
   ],
   "source": [
    "# Try creating a single pipeline that doeas full data preparation plus the final prediction\n",
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=3, cv=2, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)\n",
    "# feature_importances=rnd_search.best_estimator_.best_params_\n",
    "prepare_select_and_predict_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k)),\n",
    "    ('svm_reg', SVR(**rnd_search.best_params_))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "768a6213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:04:30.888765Z",
     "start_time": "2022-05-08T07:04:17.704483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\t [ 78685.1424422  298147.75225557  86415.85910762 147625.50312715]\n",
      "Labels:\t\t [72100.0, 279600.0, 82700.0, 112500.0]\n"
     ]
    }
   ],
   "source": [
    "prepare_select_and_predict_pipeline.fit(housing, housing_labels)\n",
    "some_data = housing.iloc[:4]\n",
    "some_labels = housing_labels.iloc[:4]\n",
    "\n",
    "print(\"Predictions:\\t\", prepare_select_and_predict_pipeline.predict(some_data))\n",
    "print(\"Labels:\\t\\t\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da9331ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:16:02.529791Z",
     "start_time": "2022-05-08T07:12:40.180739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=1, preparation__num__imputer__strategy=most_frequent; total time=   3.1s\n",
      "[CV] END feature_selection__k=1, preparation__num__imputer__strategy=most_frequent; total time=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=2, preparation__num__imputer__strategy=most_frequent; total time=   3.1s\n",
      "[CV] END feature_selection__k=2, preparation__num__imputer__strategy=most_frequent; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=3, preparation__num__imputer__strategy=most_frequent; total time=   3.1s\n",
      "[CV] END feature_selection__k=3, preparation__num__imputer__strategy=most_frequent; total time=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=4, preparation__num__imputer__strategy=most_frequent; total time=   3.0s\n",
      "[CV] END feature_selection__k=4, preparation__num__imputer__strategy=most_frequent; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=5, preparation__num__imputer__strategy=most_frequent; total time=   3.2s\n",
      "[CV] END feature_selection__k=5, preparation__num__imputer__strategy=most_frequent; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=6, preparation__num__imputer__strategy=most_frequent; total time=   3.1s\n",
      "[CV] END feature_selection__k=6, preparation__num__imputer__strategy=most_frequent; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=7, preparation__num__imputer__strategy=most_frequent; total time=   3.2s\n",
      "[CV] END feature_selection__k=7, preparation__num__imputer__strategy=most_frequent; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=8, preparation__num__imputer__strategy=most_frequent; total time=   3.1s\n",
      "[CV] END feature_selection__k=8, preparation__num__imputer__strategy=most_frequent; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=9, preparation__num__imputer__strategy=most_frequent; total time=   3.6s\n",
      "[CV] END feature_selection__k=9, preparation__num__imputer__strategy=most_frequent; total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=10, preparation__num__imputer__strategy=most_frequent; total time=   3.7s\n",
      "[CV] END feature_selection__k=10, preparation__num__imputer__strategy=most_frequent; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=11, preparation__num__imputer__strategy=most_frequent; total time=   3.7s\n",
      "[CV] END feature_selection__k=11, preparation__num__imputer__strategy=most_frequent; total time=   9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=12, preparation__num__imputer__strategy=most_frequent; total time=   3.6s\n",
      "[CV] END feature_selection__k=12, preparation__num__imputer__strategy=most_frequent; total time=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 748, in transform\n",
      "    Xs = self._fit_transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 606, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 876, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 509, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 142, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories ['ISLAND'] in column 0 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END feature_selection__k=13, preparation__num__imputer__strategy=most_frequent; total time=   4.0s\n",
      "[CV] END feature_selection__k=13, preparation__num__imputer__strategy=most_frequent; total time=   9.6s\n",
      "[CV] END feature_selection__k=14, preparation__num__imputer__strategy=most_frequent; total time=   0.0s\n",
      "[CV] END feature_selection__k=14, preparation__num__imputer__strategy=most_frequent; total time=   9.6s\n",
      "[CV] END feature_selection__k=15, preparation__num__imputer__strategy=most_frequent; total time=   0.0s\n",
      "[CV] END feature_selection__k=15, preparation__num__imputer__strategy=most_frequent; total time=   9.7s\n",
      "[CV] END feature_selection__k=16, preparation__num__imputer__strategy=most_frequent; total time=   0.0s\n",
      "[CV] END feature_selection__k=16, preparation__num__imputer__strategy=most_frequent; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "3 fits failed out of a total of 32.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\Qi\\AppData\\Local\\Temp\\ipykernel_16848\\2911709292.py\", line 13, in transform\n",
      "    return X[:, self.feature_indices_]\n",
      "IndexError: index 15 is out of bounds for axis 1 with size 15\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature_selection__k': 1,\n",
       " 'preparation__num__imputer__strategy': 'most_frequent'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically explore sopme preparations options using GridSearchCV\n",
    "full_pipeline.named_transformers_[\"cat\"].handle_unknown = 'ignore'\n",
    "\n",
    "param_grid = [{\n",
    "#    'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'preparation__num__imputer__strategy': ['most_frequent'],\n",
    "    'feature_selection__k': list(range(1, len(feature_importances) + 1))\n",
    "}]\n",
    "\n",
    "grid_search_prep = GridSearchCV(prepare_select_and_predict_pipeline, param_grid, cv=2,\n",
    "                                scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search_prep.fit(housing, housing_labels)\n",
    "\n",
    "grid_search_prep.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa2df17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T07:11:20.395791Z",
     "start_time": "2022-05-08T07:11:20.388811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 9 3 2 7 4 5 8 0]\n",
      "[4 0 3 3 5 6 7 9 8 9]\n",
      "[4 0 3 3]\n",
      "[6 9 2 3 1 7 4 5 8 0]\n",
      "[0 3 5 3 4 6 7 9 8 9]\n",
      "[7 9 8 9]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([9, 4, 5, 3, 7, 9, 0, 6, 8, 3])\n",
    "index_list = np.argpartition(a, 4)\n",
    "print(index_list) #输出为索引\n",
    "print(a[index_list]) # 可见输出最小的k个，无需严格将元素从小到大排序\n",
    "print(a[index_list][:4]) # 只保证前四个元素是最小四的\n",
    "# [1 6 9 3 2 7 4 5 8 0]\n",
    "# [4 0 3 3 5 6 7 9 8 9]\n",
    "# [4 0 3 3]\n",
    "index_list = np.argpartition(a, -4)\n",
    "print(index_list) \n",
    "print(a[index_list]) \n",
    "print(a[index_list][-4:]) # 只保证后四个元素是最大的四个\n",
    "# [6 9 2 3 1 7 4 5 8 0]\n",
    "# [0 3 5 3 4 6 7 9 8 9]\n",
    "# [7 9 8 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39993362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 446.844,
   "position": {
    "height": "40px",
    "left": "192px",
    "right": "20px",
    "top": "28px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
